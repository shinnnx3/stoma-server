# image_processing.py

import cv2

import numpy as np

import torch

from ultralytics import YOLO

from torchvision import transforms

from PIL import Image

import os



class MedicalImageProcessor:

    def __init__(self):

        # 1. Î™®Îç∏ Í≤ΩÎ°ú ÏÑ§Ï†ï (ÌòÑÏû¨ ÌååÏùº ÏúÑÏπò Í∏∞Ï§Ä models Ìè¥Îçî)

        BASE_DIR = os.path.dirname(os.path.abspath(__file__))

        self.yolo_path = os.path.join(BASE_DIR, "models", "best.pt")

        self.eff_path = os.path.join(BASE_DIR, "models", "efficientnet.pth")

        

        self.device = torch.device("cpu") # GPU ÏóÜÏúºÎ©¥ cpu ÏÇ¨Ïö©

        self.target_names = {"STOMA": "Stoma", "REF": "Tissue"}

        

        # 2. YOLO Î°úÎìú

        print(f"üîÑ Loading YOLO from {self.yolo_path}...")

        try:

            self.yolo_model = YOLO(self.yolo_path)

            print("‚úÖ YOLO Î°úÎìú ÏÑ±Í≥µ")

        except Exception as e:

            print(f"‚ö†Ô∏è YOLO Î°úÎìú Ïã§Ìå®: {e}")

            self.yolo_model = None



        # 3. EfficientNet Î°úÎìú

        print(f"üîÑ Loading EfficientNet from {self.eff_path}...")

        self.classifier = None

        try:

            self.classifier = torch.load(self.eff_path, map_location=self.device)

            self.classifier.eval()

            print("‚úÖ EfficientNet Î°úÎìú ÏÑ±Í≥µ")

        except Exception as e:

            print(f"‚ö†Ô∏è EfficientNet Î°úÎìú Ïã§Ìå® (ÏûÑÏãú Î™®ÎìúÎ°ú ÎèôÏûë): {e}")

        # Ï†ÑÏ≤òÎ¶¨ ÎèÑÍµ¨
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def _bytes_to_cv2(self, file_bytes):
        nparr = np.frombuffer(file_bytes, np.uint8)
        return cv2.imdecode(nparr, cv2.IMREAD_COLOR)

    def _cv2_to_bytes(self, img):
        success, encoded_img = cv2.imencode('.jpg', img)
        return encoded_img.tobytes() if success else None

    # (ÌåÄÏõêÏù¥ Ï§Ä ÌôîÏù¥Ìä∏Î∞∏Îü∞Ïä§ Í≥ÑÏÇ∞ Ìï®Ïàò)
    def _calculate_wb_scale(self, img, ref_box):
        if ref_box is None: return 1.0, 1.0, 1.0
        x1, y1, x2, y2 = map(int, ref_box)
        h, w, _ = img.shape
        x1, y1 = max(0, x1), max(0, y1); x2, y2 = min(w, x2), min(h, y2)
        roi = img[y1:y2, x1:x2]
        if roi.size == 0: return 1.0, 1.0, 1.0
        
        target = 240.0
        sb = min(target / (np.mean(roi[:,:,0]) + 1e-5), 3.0)
        sg = min(target / (np.mean(roi[:,:,1]) + 1e-5), 3.0)
        sr = min(target / (np.mean(roi[:,:,2]) + 1e-5), 3.0)
        return sb, sg, sr

    # (ÌåÄÏõêÏù¥ Ï§Ä Î≥¥Ï†ï Î∞è ÌÅ¨Î°≠ Ìï®Ïàò)
    def _apply_wb_crop_clahe(self, img, stoma_box, scales):
        sb, sg, sr = scales
        x1, y1, x2, y2 = map(int, stoma_box)
        h, w, _ = img.shape
        x1, y1 = max(0, x1), max(0, y1); x2, y2 = min(w, x2), min(h, y2)
        
        crop = img[y1:y2, x1:x2]
        if crop.size == 0: return None

        b, g, r = cv2.split(crop)
        b = cv2.multiply(b, sb); g = cv2.multiply(g, sg); r = cv2.multiply(r, sr)
        b, g, r = [np.clip(c, 0, 255).astype(np.uint8) for c in [b, g, r]]
        
        lab = cv2.cvtColor(cv2.merge([b, g, r]), cv2.COLOR_BGR2LAB)
        l, a, b_ch = cv2.split(lab)
        clahe = cv2.createCLAHE(clipLimit=1.5, tileGridSize=(8, 8))
        l = clahe.apply(l)
        
        return cv2.cvtColor(cv2.merge((l, a, b_ch)), cv2.COLOR_LAB2BGR)

    # ‚òÖ Î©îÏù∏ Ï≤òÎ¶¨ Ìï®Ïàò
    def process(self, file_bytes):
        original_img = self._bytes_to_cv2(file_bytes)
        if original_img is None: return {"is_valid": False}

        # YOLO Î™®Îç∏Ïù¥ ÏóÜÍ±∞ÎÇò Î°úÎìú Ïã§Ìå®Ïãú ÏïàÏ†ÑÏû•Ïπò
        if self.yolo_model is None:
            return {
                "necrosis_class": 0,
                "brightness": 0.0,
                "processed_bytes": file_bytes,
                "is_valid": True,
                "note": "AI Model Not Loaded"
            }

        # 1. YOLO ÏòàÏ∏°
        results = self.yolo_model.predict(original_img, verbose=False, conf=0.2)
        result = results[0]

        # Î∞ïÏä§ Ï∞æÍ∏∞ Î°úÏßÅ
        def get_box(lbl):
            best, max_conf = None, 0.0
            for box in result.boxes:
                cls_id = int(box.cls[0])
                if result.names[cls_id] == lbl and box.conf[0] > max_conf:
                    best, max_conf = box.xyxy[0].tolist(), float(box.conf[0])
            return best

        stoma_box = get_box(self.target_names["STOMA"])
        ref_box = get_box(self.target_names["REF"])

        # Stoma ÏóÜÏúºÎ©¥ ÏõêÎ≥∏ Î¶¨ÌÑ¥
        if stoma_box is None:
            hsv = cv2.cvtColor(original_img, cv2.COLOR_BGR2HSV)
            return {
                "necrosis_class": 0,
                "brightness": float(np.mean(hsv[:,:,2])),
                "processed_bytes": file_bytes,
                "is_valid": True,
                "note": "No stoma detected"
            }

        # 2. Î≥¥Ï†ï (WB -> Crop -> CLAHE)
        scales = self._calculate_wb_scale(original_img, ref_box)
        processed_img = self._apply_wb_crop_clahe(original_img, stoma_box, scales)
        
        if processed_img is None: return {"is_valid": False}

        # 3. EfficientNet ÏòàÏ∏°
        necrosis_class = 1
        if self.classifier:
            img_rgb = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)
            pil_img = Image.fromarray(img_rgb)
            input_tensor = self.transform(pil_img).unsqueeze(0).to(self.device)
            with torch.no_grad():
                outputs = self.classifier(input_tensor)
                _, predicted = torch.max(outputs, 1)
                necrosis_class = int(predicted.item())

        # 4. Î∞ùÍ∏∞ Í≥ÑÏÇ∞
        brightness = float(np.mean(cv2.cvtColor(processed_img, cv2.COLOR_BGR2HSV)[:,:,2]))

        return {
            "necrosis_class": necrosis_class,
            "brightness": brightness,
            "processed_bytes": self._cv2_to_bytes(processed_img),
            "is_valid": True
        }
